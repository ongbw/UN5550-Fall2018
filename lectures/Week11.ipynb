{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Theory\n",
    "\n",
    "Interpreting data as networks (a.k.a. graphs) can provide a useful way to gain insight into data.  In fact, since our world is essentially one big network, some argue that graph theory is the \"next big thing\" in data, as tools and algorithms from graph theory start to infiltrate the data science realm.  Some examples of networks and their components:\n",
    "- social network: users (vertices), interactions (edges)\n",
    "- banking: account holders (vertices), transactions (edges)\n",
    "- physician network: physicians (vertices), patients (edges)\n",
    "- supply chain: warehouses (vertices), trucks (edges)\n",
    "\n",
    "Goals for this module:\n",
    "- introduction to NetworkX\n",
    "- properties of graphs\n",
    "- visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Graphs\n",
    "We have actually already encountered networks and graphs, when we covered Laplacian Eigenmaps in the dimension reduction module.  A graph consists of vertices, edges, and weights, $G(V,E,W)$.  Graph theory is the mathematical field that provides the tools to understand and analyze networks.   We will learn about a tool called NetworkX, https://networkx.github.io/, which is the de facto  Python package for creating, manipulating, and studying the structure, dynamics, and functions of complex networks. Lets begin by creating a simple undirected graph and viewing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "G = nx.Graph()  # Create an empty graph with no nodes or edges\n",
    "\n",
    "# add nodes one at a time\n",
    "G.add_node('A')\n",
    "\n",
    "# or add a list of nodes\n",
    "G.add_nodes_from(['B', 'C', 'D'])\n",
    "\n",
    "# add edge one at a time\n",
    "G.add_edge('A', 'C')\n",
    "\n",
    "# or add a list of edges\n",
    "G.add_edges_from([('A', 'B'), ('A','D'), ('C', 'D')])\n",
    "\n",
    "# thus far we have created an undirected, unweighted graph.\n",
    "# We can retreive the number of edges and number of nodes using:\n",
    "print \"number of nodes: \", G.number_of_nodes()\n",
    "\n",
    "print \"number of edges: \", G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetworkX was not designed to be a graph drawing package, but some functionality is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nx.draw(G, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some basic reporting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report list of nodes\n",
    "list(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report list of edges\n",
    "list(G.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the degree of a node is the number of edges that connect to it, (or as we will see later for weighted graphs, the sum of the weights connected to it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report degree of node connected to \"C\"\n",
    "G.degree('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can list all neighbors of a node\n",
    "list(G.neighbors('C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or you can also use the terminology \"adjacency\" to describe neighbors\n",
    "list(G.adj['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can also remove nodes and edges in a similar fashion\n",
    "G.remove_node('C')\n",
    "\n",
    "nx.draw(G, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also define a graph with weighted edges.\n",
    "\n",
    "# clear existing graph\n",
    "G.clear()\n",
    "\n",
    "# add graph with four nodes\n",
    "G.add_nodes_from(['A','B', 'C', 'D'])\n",
    "\n",
    "# add weighted edges \n",
    "G.add_weighted_edges_from([('A', 'B',2.5), ('A','D',0.5), ('C', 'D',2.0), ('A','C',1.0)])\n",
    "\n",
    "# plot\n",
    "nx.draw(G, with_labels=True, font_weight='bold')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define a directed graph (which is useful for say, traffic flow), the DiGraph class provides additional properties specific to directed graphs.  Specifically, nodes have *two* different degre measures:\n",
    "- an in-degree, which measures the number of incoming edges\n",
    "- an out-degree, which measures the number of out-going edges.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG = nx.DiGraph()\n",
    "DG.add_nodes_from([1,2, 3,4]) # note: nodes can be any hashable object\n",
    "\n",
    "# add weighted edges \n",
    "DG.add_weighted_edges_from([(1, 2, 2.5), (1,4,0.5), (3, 4,2.0), (1,3,1.0)])\n",
    "\n",
    "# plot\n",
    "nx.draw(DG, with_labels=True, font_weight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG.out_degree(3, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG.in_degree(3, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that degree will still work, but will report the sum of the in and out degree\n",
    "DG.degree(3, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or if you just want to count the edges\n",
    "DG.degree(3, weight=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path between nodes\n",
    "\n",
    "Another basic definition we need in a graph, is the notion of a path between two nodes, i.e., the set of edges one traverses to go from one node to another.  In many applications, one cares about the shortest permitted path between two nodes (sum of the weights of the edges connecting the two nodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected / Disconnected graphs\n",
    "\n",
    "Before we introduce the concept of connectivity, we need to define connected and disconnected graphs.  \n",
    "- A graph is *connected* when there is a path between every pair of vertices. In a connected graph, there is no unreachable vertex. \n",
    "- A graph that is not connected is *disconnected*. A graph G is said to be disconnected if there exist two nodes in G such that no path in G has those nodes as endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an example of a connected graph\n",
    "G = nx.Graph()  \n",
    "G.add_nodes_from(['A','B', 'C', 'D'])\n",
    "G.add_edges_from([('A','C'),('A', 'B'), ('A','D'), ('C', 'D')])\n",
    "nx.draw(G, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an example of a disconnected graph\n",
    "G = nx.Graph()  \n",
    "G.add_nodes_from(['A','B', 'C', 'D'])\n",
    "G.add_edges_from([('A', 'B'), ('C', 'D')])\n",
    "nx.draw(G, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A connected component is a maximal connected subgraph of G -- each vertex belongs to exactly one connected component, as does each edge.  The number of *connected components* is the number of subgraphs (subsets of nodes and edges linking those nodes) that are connected.  In the above example, there are two connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"# of connected components = \", nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectivity\n",
    "\n",
    "Connectivity: the minimum number of elements (nodes or edges) that need to be removed to disconnect the remaining nodes from each other.  Some simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this graph becomes disconnected with the edge CD is removed.\n",
    "G = nx.Graph()  \n",
    "G.add_nodes_from(['A','B', 'C', 'D','E','F'])\n",
    "G.add_edges_from([('A','B'),('A', 'C'), ('B','C'), ('C', 'D'),('D','E'),('D','F'),('E','F')])\n",
    "nx.draw(G, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this graph becomes disconnected with the node C\n",
    "G = nx.Graph() \n",
    "G.add_nodes_from(['A','B', 'C', 'D','E'])\n",
    "G.add_edges_from([('A','B'),('A', 'C'), ('B','C'), ('C', 'D'),('C','E'),('D','E')])\n",
    "nx.draw(G, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A (vertex) *cut* is defined as a set of vertices whose removal renders the graph disconnected.  In the above example, this is the vertex C.  Since this set only has one element, we say that the graph G has connectivity 1, the size of the minimal vertex cut.  If the set has $k$ elements, we say that the graph G has connectivity $k$.   A graph is called *k-connected* if its vertex connectivity is $k$ or greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dG = nx.DiGraph()\n",
    "dG.add_edge('x','a', capacity = 3.0)\n",
    "dG.add_edge('x','b', capacity = 1.0)\n",
    "dG.add_edge('a','c', capacity = 3.0)\n",
    "dG.add_edge('b','c', capacity = 5.0)\n",
    "dG.add_edge('b','d', capacity = 4.0)\n",
    "dG.add_edge('d','e', capacity = 2.0)\n",
    "dG.add_edge('c','y', capacity = 2.0)\n",
    "dG.add_edge('e','y', capacity = 3.0)\n",
    "nx.draw(dG, with_labels=True, font_weight='bold')\n",
    "cut_value, partition = nx.minimum_cut(dG,'x','y')\n",
    "print(cut_value)\n",
    "print(partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the graph seperators problems (identifying cuts) have been proven to be NP-hard.  There are a wealth of algorithms to estimate connectivity and identify cuts, but deterministic algorithms are computationally intractable for a large number of vertices.  One of the more promising algorithms I have seen was discussed in this manuscript, https://doi.org/10.1016/j.jocs.2016.10.005, where the algorithm could find 3-vertex seperators for 25k vertices.  The R scripts at https://github.com/sinkovit/k-components and are not implemented in Python yet.  This would make a good project for someone wanting to contribute a useful algorithm upstream to NetworkX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality\n",
    "\n",
    "The centrality of a vertex measures the relative importance of the vertex within the graph.  This concept was first developed in social network analysis, hence, many of the terms and concepts reflect the sociological origin.  In social network analysis, one often seeks to identify the most influential people, the most informed people, or the most communicative people.  Indeed, there are various popular measures for centrality based on the application/question.  Unfortunately, a choice that is optimal for one application is often sub-optimal for a different application.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree centrality\n",
    "\n",
    "The simplest measure is degree centrality, which is defined as the number of edges connected to a node.  This was historically the first measure proposed, and is understood in terms of the capacity coming in to the node (indegree) and leaving the node (outdegree).  To compare between graphs, one often scales the degree by $(N-1)$, where $N$ is the number of vertices in the graph.  Computing degree centrality takes O(N^2) operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closeness centrality\n",
    "\n",
    "Closeness centrality measures the average length of the shortest path between the node and all other nodes in the graph.  The closeness was defined by Bavelas (1950, \"Communication Patterns in task-Oriented Groups\") as\n",
    "\\begin{align}\n",
    "C(x) = \\frac{1}{\\sum_y d(y,x)}\n",
    "\\end{align}\n",
    "There are several algorithm choices for finding the shortest path.  For dense graphs, this typically takes $O(N^3)$ operations.  By construction, it only makes sense to talk about closeness centrality when you have a connected graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness centrality\n",
    "\n",
    "This measure of centrality quantifies the number of times a node acts as a bridge along the shortest path between other nodes.  It was introduced by Freeman (1977, \"A set of measures of centrality based upon betweenness\" as a measure for quantifying the control of a human on the communication between other humans in a social network.  The betweenness of a vertex $v$ is computed as follows\n",
    "- for each pair of vertices $(s,t)$, compute the shortest path between them\n",
    "- for each pair of vertices $(s,t)$, determine the fraction of paths that pass through vertex $v$\n",
    "- sum this fraction over all pairs of vertices $(s,t)$.\n",
    "\n",
    "Like the closeness centrality, betweenness centrality typically takes $O(N^3)$ operations.  Again by construction, it only makes sense to talk about closeness centrality when you have a connected graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvector centrality\n",
    "\n",
    "Eigenvector centrality is a natural extension of degree centrality. The idea is to define a relative score for a vertex based on the quality connections: connections from high centrality nodes contribute more to the score of a node than connections from a low centrality score.  Google's PageRank was a variant of this idea.  It is called the eigenvector centrality because it can be posed as an eigenvalue problem.\n",
    "\n",
    "Let $A$ be the adjacency matrix for a graph $G$, i,e, $A_{ij} = 1$ if there is an edge connecting vertex $i$ and $j$, 0 otherwise.  We want the centrality score for node $i$, denote this as $x_i$, to be proportional to the sum of the scores of all the nodes that are connected to it, i.e.\n",
    "\\begin{align*}\n",
    "  x_i = c \\sum_{j \\in M(i)} x_j\n",
    "\\end{align*}\n",
    "where $M(i)$ are nodes in the neighborhood (i.e. connected) to node $i$.  Here, $c$ is a constant.  We can simplify this sum by using the adjacency matrix\n",
    "\\begin{align*}\n",
    "  x_i = c \\sum_{j=1}^N A_{ij} x_j\n",
    "\\end{align*}\n",
    "A vector of centrality scores, $\\vec{x}$, thus satisfies\n",
    "\\begin{align*}\n",
    "  \\vec{x} = c A \\vec{x}.\n",
    "\\end{align*}\n",
    "If we take $c = \\frac{1}{\\lambda}$, and rearrange, we recover the standard eigenvalue problem:\n",
    "\\begin{align*}\n",
    "A \\vec{x} = \\lambda \\vec{x}\n",
    "\\end{align*}\n",
    "We desire centrality measures, $\\vec{x}$, that are non-negative.  There is a mathematical theorem (the Perron-Frobenius theorem) that asserts that the eigenvector associated with the largest eigenvalue results in the desired centrality measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Lets explore centrality measures on a toy graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()  \n",
    "G.add_nodes_from(['A','B', 'C', 'D','E','F'])\n",
    "G.add_edges_from([('A','B'),('A', 'C'), ('B','C'), ('C', 'D'),('D','E'),('D','F'),('E','F')])\n",
    "nx.draw(G, with_labels=True, font_weight='bold')\n",
    "\n",
    "deg_cent = nx.degree_centrality(G)\n",
    "print \"degree centrality: \", deg_cent\n",
    "\n",
    "betw_cent = nx.betweenness_centrality(G)\n",
    "print \"betweenness  centrality: \", betw_cent\n",
    "\n",
    "close_cent = nx.closeness_centrality(G)\n",
    "print \"closeness  centrality: \", close_cent\n",
    "\n",
    "eig_cent = nx.eigenvector_centrality(G)\n",
    "print \"eigenvector  centrality: \", eig_cent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Example\n",
    "\n",
    "Okay, lets now use NetworkX to study part of the Facebook dataset from the Stanford Large Network Dataset Collection, which is an undirected graph consisting of node features (profiles), circles, and ego networks, https://snap.stanford.edu/data/ego-Facebook.html.  The datafile below contains on each line, an edge definition connecting two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = nx.Graph() \n",
    "fb = nx.read_edgelist(\"data/facebook_data.txt\")\n",
    "print \"number of nodes: \", fb.number_of_nodes()\n",
    "print \"number of edges: \", fb.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this data set has 4,039 users and 88,234 friendship connections, so each user has (on average) 21 friendship connections.  It is often useful to visualize a histogram of the degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dict(fb.degree()).values(),100)\n",
    "plt.ylabel(\"frequency\")\n",
    "_ = plt.xlabel(\"degree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the degree distribution of this network follows a \"power-law\", one can refer to this as a *scale-free* network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dict(fb.degree()).values(),100)\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xlabel(\"degree\")\n",
    "_ = plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also measure the centrality distribution of nodes in the network.  \n",
    "# First, we should make sure that we have a connected graph, i.e., only one connected component\n",
    "\n",
    "print \"# connected components = \", nx.number_connected_components(fb)\n",
    "plt.subplot(2,1,1)\n",
    "plt.hist(dict(nx.degree_centrality(fb)).values(),100)\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.yscale('log')\n",
    "_ = plt.xlabel(\"degree centrality\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.hist(dict(nx.eigenvector_centrality(fb)).values(),100)\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.yscale('log')\n",
    "_ = plt.xlabel(\"eigenvector centrality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other two centrality measures take too long to run for a demo.  Both graphs show, that a large majority of the nodes have low centrality.  We can try to trim the network, dropping nodes that have less than the average degree of the network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_degree_centrality(graph, degree = 0.01):\n",
    "    g = graph.copy()\n",
    "    d = nx.degree_centrality(g)\n",
    "    for n in graph.nodes():\n",
    "    #    print(d[n])\n",
    "        if d[n] <= degree:\n",
    "            g.remove_node(n)\n",
    "    return g\n",
    "\n",
    "threshold = 21.0/(fb.number_of_nodes() - 1)\n",
    "trim_fb = trim_degree_centrality(fb, degree = threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"number of nodes: \", trim_fb.number_of_nodes()\n",
    "print \"number of edges: \", trim_fb.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully removed half the nodes. Lets see if we can now plot the various centrality measures...\n",
    "First, we should check if the graph is still connected for some o the centrality measures to make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"# connected components = \", nx.number_connected_components(trim_fb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oops.  looks like we now have a disconnected graph.  lets look at the subgraphs and pick an appropriate one to study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_subgraph = list(nx.connected_component_subgraphs(trim_fb))\n",
    "\n",
    "# check number of components of each subgraph\n",
    "print \"nodes in subgraph [0]: \", len(fb_subgraph[0])\n",
    "print \"nodes in subgraph [1]: \", len(fb_subgraph[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess only one node was disconnected.  lets measure the centrality distribution of the larger subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also measure the centrality distribution of nodes in the network\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(dict(nx.degree_centrality(fb_subgraph[0])).values(),100)\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.yscale('log')\n",
    "_ = plt.xlabel(\"degree centrality\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(dict(nx.closeness_centrality(fb_subgraph[0])).values(),100)\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.yscale('log')\n",
    "_ = plt.xlabel(\"closeness centrality\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(dict(nx.betweenness_centrality(fb_subgraph[0])).values(),100)\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.yscale('log')\n",
    "_ = plt.xlabel(\"betweenness centrality\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(dict(nx.eigenvector_centrality(fb_subgraph[0])).values(),100)\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.yscale('log')\n",
    "_ = plt.xlabel(\"eigenvector centrality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not going to get into parallel processing in this class, but the betweenness/closeness centrality measures are computational intensive, but conveniently, pleasantly parallel.  With a little bit of effort, one can use multiple threads to compute shortest paths using the multi-processing toolbox to accelerate the centrality computation:   https://networkx.github.io/documentation/networkx-1.9/examples/advanced/parallel_betweenness.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Visualization\n",
    "\n",
    "We can make use of centrality to aid the visualization of graphs.  Suppose we just used a random layout of nodes to visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (6,6))\n",
    "\n",
    "pos = nx.random_layout(fb)\n",
    "nx.draw_networkx(fb, pos, with_labels = False)\n",
    "\n",
    "#get current figure\n",
    "ax = plt.gca()\n",
    "ax.collections[0].set_edgecolor('#000000') # outline nodes with black\n",
    "_ = plt.axis('off') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't provide any insight into the network.  if we pick the position of the vertices more intelligently, for example using the spring_layout functionality (the default in nx.draw), we start to gain more intuition about the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (6,6))\n",
    "nx.draw(fb)\n",
    "#get current figure\n",
    "ax = plt.gca()\n",
    "_ = ax.collections[0].set_edgecolor('#000000') # outline nodes with black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function nx.spring_layout returns the position of the nodes using the Fruchtermanâ€“Reingold force-directed algorithm. This algorithm distributes the graph nodes in such a way that all the edges are more or less equally long and they cross themselves as few times as possible. Moreover, we can change the size of the nodes to that defined by their degree centrality.  We recreate the plot, but this time, allowing the algorithm to iterate further than the default.  Then, we vary the size of the node to it's centrality measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_fb = nx.spring_layout(fb, iterations=100) # default is 50\n",
    "\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "degree_cent_fb = nx.degree_centrality(fb)\n",
    "nsize = np.array([v for v in degree_cent_fb.values()])\n",
    "cte = 500\n",
    "nsize = cte*(nsize  - min(nsize))/(max(nsize)-min(nsize))\n",
    "nodes=nx.draw_networkx_nodes(fb, pos = pos_fb, node_size = nsize, with_labels = True)\n",
    "edges=nx.draw_networkx_edges(fb, pos = pos_fb, alpha = .1, with_labels = True)\n",
    "ax = plt.gca()\n",
    "ax.collections[0].set_edgecolor('#000000') # outline nodes with black\n",
    "_ = plt.axis('off') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book shows various renditions of network visualization using different centrality measures to vary the size of the nodes (Figures 8.6 -- 8.9).  Additionally, figure 8.10 shows that rendition when page rank is used to determine the size of the node.  As mentioned earlier, the page rank algorithm is a variant of the eigenvector centrality measure.  The difference, is they generate a Markov transition matrix, $M$, to mimic a random walk through the network.  Applying this transition matrix iteratively results in a page rank vector, whose $i$-th entry corresponds to a web surfer visiting page $i$.  There is a built-in networkX command to compute the pagerank vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank(fb, alpha=0.85)\n",
    "nsize = np.array([v for v in pr.values()])\n",
    "cte = 500\n",
    "nsize = cte*(nsize  - min(nsize))/(max(nsize)-min(nsize))\n",
    "nodes=nx.draw_networkx_nodes(fb, pos = pos_fb, node_size = nsize, with_labels = True)\n",
    "edges=nx.draw_networkx_edges(fb, pos = pos_fb, alpha = .1, with_labels = True)\n",
    "ax = plt.gca()\n",
    "ax.collections[0].set_edgecolor('#000000') # outline nodes with black\n",
    "_ = plt.axis('off') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
